{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainer notebook for Copenhagen visualizations by Jamie and Valentin\n",
    "\n",
    "Below is the code and some static graphs used for processing the data used in our project for exploring the city of Copenhagen.\n",
    "The code is split into the sections that roughly corresponds to the website.\n",
    "\n",
    "N.B. the code will generate files from the relative path \"src/data/\" so remember to have the whole project folder downloaded to avoid errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, setup and Introduction\n",
    "We'll import a data set here that is based on peoples age, their income and the district they live in.\n",
    "\n",
    "We have cleaned the data before importing it and removed unused columns. We have also removed rows with _bad_ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, collections, csv\n",
    "import pandas as pd, matplotlib as mat, matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "root_directory = os.path.abspath(os.pardir)\n",
    "df = pd.read_csv(os.path.join(root_directory, \"src\",\"data\",\"kon_alder_bydel_penge.csv\")) # reads csv\n",
    "\n",
    "print df.head()\n",
    "print \"shape:\",df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh, oh. The entries are summed by persons for the categories. Later we'll need the entries to be one individual. Let's repeat on the person count to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_repeated = df.loc[df.index.repeat(df['Personer'])].copy().reset_index(drop=True)\n",
    "df_repeated.drop('Personer', axis=1, inplace=True)\n",
    "\n",
    "print df_repeated.head()\n",
    "print \"shape:\",df_repeated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better. We now have $473291$ entries instead of $705$.\n",
    "\n",
    "Let's take a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show number of people in each district\n",
    "print df.groupby(['Bydel'])['Personer'].sum(),\"\\n\"\n",
    "print df.groupby(['Aldersgruppe'])['Personer'].sum(),\"\\n\"\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.\n",
    "We know that there are many tall buildings on Nørrebro and more villas and Brønshøj-Husum which can contribute to the difference in the population count of the districts. The area of the districts also vary though.\n",
    "\n",
    "We can see the that the age group _30-64_ years old has the most people in it. It is also the group spanning the most years so it makes sense. Though it is more than three times as _wide_ as the _20-29_ group it has slightly less than two times as many people in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People in age groups listed by districts\n",
    "Let's try to see the distribution here.\n",
    "A lot of data processing to calculate the ratio between age groups in different districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "Districts = df.Bydel.unique()\n",
    "age_categories = df.Aldersgruppe.unique()\n",
    "\n",
    "# Total number of people, and people in an age category\n",
    "total_people = df['Personer'].sum()\n",
    "people_in_age_category = df.groupby(['Aldersgruppe'])['Personer'].sum().astype(float)\n",
    "\n",
    "# Create dictionary with ratios\n",
    "age_category_sum = []\n",
    "for category in age_categories:\n",
    "    age_category_sum.append((category, (people_in_age_category[category] / total_people)))\n",
    "age_category_sum_dict = dict(age_category_sum)\n",
    "\n",
    "\n",
    "# Three subplots sharing both x/y axes\n",
    "f, axarr = plt.subplots(5,2, sharey=True, sharex=True, figsize=(10,10))\n",
    "\n",
    "# Loop through districts and calculate ratio of people living in a district by their age category\n",
    "index = 0\n",
    "jj = 0\n",
    "people_in_districts_as_ratio = {}\n",
    "for district in Districts:\n",
    "    people_in_districts_as_ratio[district] = {}\n",
    "    people_in_district = df[df['Bydel'].isin([district])].groupby(['Aldersgruppe'])['Personer'].sum().astype(float)\n",
    "    total_people_in_district = people_in_district.sum()\n",
    "    for category in age_categories:\n",
    "        try:\n",
    "            people_in_districts_as_ratio[district][category] = (people_in_district[category] / total_people_in_district)\n",
    "        except KeyError:\n",
    "            people_in_districts_as_ratio[district][category] = 0\n",
    "    \n",
    "    d_temp = collections.OrderedDict(sorted(people_in_districts_as_ratio[district].items()))\n",
    "    axarr[index%5, index%2].set_title(district.decode('utf-8'))\n",
    "    h = axarr[index%5, index%2].bar(range(len(d_temp)), d_temp.values(), color=\"blue\")\n",
    "\n",
    "    index += 1\n",
    "    \n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.sca(axarr[0, 1])\n",
    "plt.xticks(rotation=90)\n",
    "for ax in f.axes:\n",
    "    mat.pyplot.sca(ax)\n",
    "    xticks_pos = [0.65*patch.get_width() + patch.get_xy()[0] for patch in h]\n",
    "    plt.xticks(xticks_pos, age_categories,  ha='right', rotation=45)\n",
    "\n",
    "# Show the plots!\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we can see here that the age group _30-64 years_ is the highest represented (but also the one spanning the most years, except for _65 and above_, unless we take average length of human lives into account).\n",
    "\n",
    "Furthermore the distribution looks pretty consistent on all the city districts. There are only slight variations visually noticeable.\n",
    "E.g. _Nørrebro_ has a lot of people in the _20-29 years_ group compared to _Brønshøj-Husum_ which has a lot fewer. Actually the ratio of _20-29 years_ old is twice as high on _Nørrebro_ than it is in _Brønshøj-Husum_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll just create a file here to plot the ratios on the webpage\n",
    "data = pd.DataFrame(people_in_districts_as_ratio)\n",
    "data.to_csv(\"personeriprocent.csv\", sep=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average income by district\n",
    "We could look at the income by age category as well, but we all probably know how that one will look.\n",
    "\n",
    "Instead let's take a look at the distribution between the different districts.\n",
    "\n",
    "This is much like the previous code. Slight alterations have been made to account for the new category we're looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create list of categories\n",
    "income_categories = df.Brutto.unique()\n",
    "\n",
    "# Three subplots sharing both x/y axes\n",
    "f, axarr = plt.subplots(5,2, sharey=True, sharex=True, figsize=(10,10))\n",
    "\n",
    "# Loop through districts and calculate ratio of people living in a district by their age category\n",
    "index = 0\n",
    "jj = 0\n",
    "temp = {}\n",
    "for district in Districts:\n",
    "    temp[district] = {}\n",
    "    income_in_district = df[df['Bydel'].isin([district])].groupby(['Brutto'])['Personer'].sum().astype(float)\n",
    "    total_people_district = income_in_district.sum()\n",
    "    for category in income_categories:\n",
    "        try:\n",
    "            temp[district][category] = income_in_district[category] / total_people_district\n",
    "        except KeyError:\n",
    "            temp[district][category] = 0\n",
    "    \n",
    "    d_temp = collections.OrderedDict(sorted(temp[district].items()))\n",
    "    axarr[index%5, index%2].set_title(district.decode('utf-8'))\n",
    "    h = axarr[index%5, index%2].bar(range(len(d_temp)), d_temp.values(), color=\"blue\")\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.sca(axarr[0, 1])\n",
    "plt.xticks(rotation=90)\n",
    "for ax in f.axes:\n",
    "    mat.pyplot.sca(ax)\n",
    "    xticks_pos = [0.65*patch.get_width() + patch.get_xy()[0] for patch in h]\n",
    "    plt.xticks(xticks_pos, income_categories,  ha='right', rotation=45)\n",
    "\n",
    "# Show the plots!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a first glance it looks normally distributed with a positive skew for most of the districts.\n",
    "There is though a huge difference between the wealthiest and the poorest districts. \n",
    "Let's try to see the same chart with only the 3 highest income intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of categories\n",
    "income_categories = df.Brutto.unique()[-3:]\n",
    "\n",
    "\n",
    "# Three subplots sharing both x/y axes\n",
    "f, axarr = plt.subplots(5,2, sharey=True, sharex=True, figsize=(10,10))\n",
    "\n",
    "# Loop through districts and calculate ratio of people living in a district by their age category\n",
    "index = 0\n",
    "jj = 0\n",
    "temp = {}\n",
    "for district in Districts:\n",
    "    temp[district] = {}\n",
    "    income_in_district = df[((df.Kategori == 8) \n",
    "                   | (df.Kategori == 9)\n",
    "                   | (df.Kategori == 10))\n",
    "                   & df['Bydel'].isin([district])].groupby(['Brutto'])['Personer'].sum().astype(float)\n",
    "    total_people_district = income_in_district.sum()\n",
    "    for category in income_categories:\n",
    "        try:\n",
    "            temp[district][category] = income_in_district[category] / total_people_district\n",
    "        except KeyError:\n",
    "            temp[district][category] = 0\n",
    "    \n",
    "    d_temp = collections.OrderedDict(sorted(temp[district].items()))\n",
    "    axarr[index%5, index%2].set_title(district.decode('utf-8'))\n",
    "    h = axarr[index%5, index%2].bar(range(len(d_temp)), d_temp.values(), color=\"blue\")\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "plt.sca(axarr[0, 1])\n",
    "plt.xticks(rotation=90)\n",
    "for ax in f.axes:\n",
    "    mat.pyplot.sca(ax)\n",
    "    xticks_pos = [0.65*patch.get_width() + patch.get_xy()[0] for patch in h]\n",
    "    plt.xticks(xticks_pos, income_categories,  ha='right', rotation=45)\n",
    "\n",
    "# Show the plots!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing up\n",
    "Okay let's calculate some descriptive statistics about our population.\n",
    "We will calculate the mean and median for Copenhagen as well as for the individual districts.\n",
    "To do this we must first assume that the data is uniformly distributed within our bucket categories.\n",
    "We use the following formula to calculate the median\n",
    "$$ L_m + \\left [ \\frac { \\frac{N}{2} - F_{m-1} }{f_m} \\right ] \\cdot c $$\n",
    "\n",
    "And to calculate the mean $\\mu$ we simply calculate the mean $\\mu_2$ of an interval and use that to calculate $\\mu$.\n",
    "\n",
    "According to Danmarks Statistik (DST) the mean income in Copenhagen is $261.882$ DKK, and the mean age is $35,9$ years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_sum_income = df.groupby(['Brutto'])['Personer'].sum().astype(float)\n",
    "people_sum_age = df.groupby(['Aldersgruppe'])['Personer'].sum().astype(float)\n",
    "#Lm is the lower class boundary of the group containing the median\n",
    "#n is the total number of values\n",
    "#Fm_old is the cumulative frequency of the groups before the median group\n",
    "#Fm is the frequency of the median group\n",
    "#c is the group width\n",
    "income_category_list = [\n",
    "    (0,49999),\n",
    "    (50000,99999),\n",
    "    (100000,149999),\n",
    "    (150000,199999),\n",
    "    (200000,299999),\n",
    "    (300000,399999),\n",
    "    (400000,499999),\n",
    "    (500000,599999),\n",
    "    (600000,699999),\n",
    "    (700000,1000000) # Larger interval here to \"capture\" more of the incomes above 700.000\n",
    "]\n",
    "age_category_list = [\n",
    "        (15,19),\n",
    "        (20,29),\n",
    "        (30,64),\n",
    "        (65,80) # Interval goes up to average lifespan in Denmark\n",
    "]\n",
    "\n",
    "def median(data, category):\n",
    "    result = 0\n",
    "    N = data.sum()\n",
    "    Median_group = N/2\n",
    "    Lm = 0\n",
    "    c = 0\n",
    "    fm = 0\n",
    "    Fm_old = 0\n",
    "    cumsum = 0\n",
    "    index = 0\n",
    "    for ii in data:\n",
    "        cumsum = ii + cumsum\n",
    "        if cumsum >= Median_group: # find the median group so we calculate the median for the right group\n",
    "            Lm = category[index][0]\n",
    "            c = category[index][1] - category[index][0]\n",
    "            fm = ii\n",
    "            result = Lm + ((N/2 - Fm_old)/fm) * c\n",
    "            break\n",
    "        Fm_old = Fm_old + ii\n",
    "        index = index+1\n",
    "        \n",
    "    return result    \n",
    "        \n",
    "\n",
    "income_category_mean = [\n",
    "        (0+49999)/2.0,\n",
    "        (50000+99999)/2.0,\n",
    "        (100000+149999)/2.0,\n",
    "        (150000+199999)/2.0,\n",
    "        (200000+299999)/2.0,\n",
    "        (300000+399999)/2.0,\n",
    "        (400000+499999)/2.0,\n",
    "        (500000+599999)/2.0,\n",
    "        (600000+699999)/2.0,\n",
    "        (700000+300000)/1.0\n",
    "]\n",
    "age_category_mean = [\n",
    "        (15+19)/2.0,\n",
    "        (20+29)/2.0,\n",
    "        (30+64)/2.0,\n",
    "        (65+80)/2.0\n",
    "]\n",
    "def mean(data, category):\n",
    "    people_sum_total = data.sum()\n",
    "    \n",
    "    mean_list = [y*x for x,y in zip(category, data.values)]\n",
    "    mu = (sum(mean_list))/(people_sum_total)\n",
    "    return mu\n",
    "\n",
    "print 'Copenhagen'\n",
    "print '-' * len('Copenhagen')\n",
    "print 'median income: {0:.0f} DKK'.format(median(people_sum_income, income_category_list))\n",
    "print 'mean income: {0:.0f} DKK'.format(mean(people_sum_income,income_category_mean))\n",
    "print 'median age: {0:.2f} years'.format(median(people_sum_age, age_category_list))\n",
    "print 'mean age: {0:.2f} years'.format(mean(people_sum_age,age_category_mean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the calculated mean income for Copenhagen is $255.109$ DKK which is only a $2,6\\%$ deviation from the statistics from DST.\n",
    "The situation is a bit different for the mean age, calculated to be $42,5$ years deviates $16,8\\%$ from the DST statistics. It is due to the assumption about the data being uniformly distributed and setting the maximum of the last interval to the expected lifespan when we know there are fewer people who are $80$ years old than there are people that are $60$ years old.\n",
    "There is no data we can hold the calculated medians up against, but they seem reasonable as we might expect extreme values to not have as big an influence on the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "my_dict = {}\n",
    "table = PrettyTable()\n",
    "# calculate means and medians again for all districts\n",
    "table.field_names = [\"District\", \"Mean Income\", \"Median Income\", \"Mean Age\", \"Median Age\"]\n",
    "for district in Districts:\n",
    "    people_sum_age = df[df['Bydel'] == district].groupby(['Aldersgruppe'])['Personer'].sum().astype(float)\n",
    "    people_sum_income = df[df['Bydel'] == district].groupby(['Brutto'])['Personer'].sum().astype(float)\n",
    "    my_dict[district] = [\n",
    "        \"{0:.0f}\".format(mean(people_sum_income,income_category_mean)),\n",
    "        \"{0:.0f}\".format(median(people_sum_income, income_category_list)),\n",
    "        \"{0:.0f}\".format(mean(people_sum_age,age_category_mean)),\n",
    "        \"{0:.0f}\".format(median(people_sum_age, age_category_list))\n",
    "    ]\n",
    "    table.add_row([district, my_dict[district][0], my_dict[district][1], my_dict[district][2], my_dict[district][3]])\n",
    "       \n",
    "\n",
    "print table.get_string(sortby=\"Mean Income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see a difference in the different districts. For example\n",
    "_Brønshøj_ has the highest mean age at $45,0$ years\n",
    "_Nørrebro_ has the lowest at $39,3$ years.\n",
    "_Bispebjerg_ has the lowest mean income and _Indre By_ has the highest with a $33.1\\%$ difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning: Progression or Regression?\n",
    "We will now look into machine learning to see if it is possible to train models to predict in which district a person lives based on the attributes we have in our dataset\n",
    "\n",
    "As we will see in the following part.\n",
    "This dataset is not very well suited for linear or logistic regression.\n",
    "\n",
    "We will start by plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn import preprocessing\n",
    "\n",
    "xs = preprocessing.LabelEncoder().fit_transform(df['Aldersgruppe'])\n",
    "ys = preprocessing.LabelEncoder().fit_transform(df['Kategori'])\n",
    "zs = preprocessing.LabelEncoder().fit_transform(df['Bydel'])\n",
    "\n",
    "fig = plt.figure(figsize=(8,5), facecolor='w')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs, ys, zs)\n",
    "ax.set_xlabel('Age group')\n",
    "ax.set_ylabel('Income group')\n",
    "ax.set_zlabel('District')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty evident that the data lies in the four age categories, the ten income categories and the 10 city districts.\n",
    "\n",
    "Let's move on to making a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model, decomposition\n",
    "\n",
    "target = df['Bydel']\n",
    "vectorizer = DV( sparse = False )\n",
    "train_dict = df[['Kategori', 'Aldersgruppe']].T.to_dict().values()\n",
    "X = vectorizer.fit_transform(train_dict)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "maxScore = 0\n",
    "minScore = 100\n",
    "for x in range(250):\n",
    "    X_train, X_test, target_train, target_test = train_test_split( X, target, test_size=0.1)\n",
    "    logistic.fit(X_train, target_train)\n",
    "    tmp = logistic.score(X_test, target_test)\n",
    "    if tmp > maxScore:\n",
    "        maxScore = tmp\n",
    "    if tmp < minScore:\n",
    "        minScore = tmp\n",
    "print \"max score: {0:.2f}%\".format(maxScore*100)\n",
    "print \"min score: {0:.2f}%\".format(minScore*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that the model scores very poorly. \n",
    "The data is also multi-class instead of binary which makes score a harsh prediction for the logistic regression model.\n",
    "Running the fit and score function on several splits on the data shows we get a score in the range of $0-7\\%$.\n",
    "Random guessing would give us a mean score of $10\\%$ which shows how bad this model is.\n",
    "\n",
    "To increase the score of the model we will use Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# target = df_repeated['Bydel']\n",
    "# train_dict = df_repeated[['Kategori', 'Aldersgruppe', 'Køn']].T.to_dict().values()\n",
    "# X = vectorizer.fit_transform(train_dict)\n",
    "\n",
    "# X_train, X_test, target_train, target_test = train_test_split( X, target, test_size=0.1)\n",
    "\n",
    "# logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# pca = decomposition.RandomizedPCA()\n",
    "# pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# pipe.fit(X_train, target_train)\n",
    "\n",
    "# # Example code from sklearns documentation\n",
    "# ###############################################################################\n",
    "# # Plot the PCA spectrum\n",
    "# pca.fit(X)\n",
    "# plt.figure(1, figsize=(4, 3))\n",
    "# plt.clf()\n",
    "# plt.axes([.2, .2, .7, .7])\n",
    "# plt.plot(pca.explained_variance_, linewidth=2)\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('n_components')\n",
    "# plt.ylabel('explained_variance')\n",
    "\n",
    "# ###############################################################################\n",
    "# # Prediction\n",
    "\n",
    "# n_components = [1, 2, 3, 4]\n",
    "# Cs = np.logspace(-2, 2, 1)\n",
    "\n",
    "# estimator = GridSearchCV(pipe,\n",
    "#                          dict(pca__n_components=n_components,\n",
    "#                               logistic__C=Cs))\n",
    "# estimator.fit(X_train, target_train)\n",
    "\n",
    "# plt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,\n",
    "#             linestyle=':', label='n_components chosen')\n",
    "# plt.legend(prop=dict(size=12))\n",
    "# plt.show()\n",
    "# print estimator.predict(X_test)\n",
    "# print \"max score: {0:.2f}%\".format(estimator.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're up to a whopping $15-17\\%$ now! (Just kidding). That is only slightly better than guessing at random.\n",
    "Let's see what decision trees can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisions, decisions, decisions\n",
    "Time to look at some decision trees.\n",
    "As we saw ealier the some features are more representative for a district than others, for expample, income might be an important feature to take into consideration when determining where a person lives, while gender most likely is not.\n",
    "\n",
    "In order to predict where a person lives, we have chosen four datasets to train our decision tree classifiers, which in addition to being classified per district also contains information on:\n",
    "* Dataset1 - Age, sex and income\n",
    "* Dataset2 - Ownership and living space\n",
    "* Dataset3 - Civil status and number of children\n",
    "* Dataset4 - Ancestry, education and age\n",
    "\n",
    "These data sets have no relation to eachother, they are produced by individual surveys and some represent features per habitant and others are features per residence.\n",
    "We can therefore not train a deccision tree to take all of this data into account, what we have done instead is to train four seperate decision trees, one for each of the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.preprocessing import Imputer\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "# load in datasets\n",
    "df_KABP = pd.read_csv(os.path.join(root_directory, \"src\",\"data\",\"kon_alder_bydel_penge.csv\")) # reads csv\n",
    "df_KABP_repeated = df_KABP.loc[df_KABP.index.repeat(df_KABP['Personer'])].copy().reset_index(drop=True)\n",
    "\n",
    "df_BEA = pd.read_csv(os.path.join(root_directory, \"src\",\"data\",\"boliger_ejerforhold_areal.csv\")) # reads csv\n",
    "df_BEA_repeated = df_BEA.loc[df_BEA.index.repeat(df_BEA['Antal boliger'])].copy().reset_index(drop=True)\n",
    "\n",
    "df_AHU = pd.read_csv(os.path.join(root_directory, \"src\",\"data\",\"Alder_herkomst_uddanelse.csv\")) # reads csv\n",
    "df_AHU_repeated = df_AHU.loc[df_AHU.index.repeat(df_AHU['Personer'])].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_CB = pd.read_csv(os.path.join(root_directory, \"src\",\"data\",\"civilstatus_born.csv\")) # reads csv\n",
    "df_CB_repeated = df_CB.loc[df_CB.index.repeat(df_CB['Antal'])].copy().reset_index(drop=True)\n",
    "def createDT (data, target):\n",
    "    \n",
    "    vectorizer = DV( sparse = False )\n",
    "    train_dict = data.T.to_dict().values()\n",
    "    X = vectorizer.fit_transform(train_dict)\n",
    "    print X.shape\n",
    "    print data.shape\n",
    "    X_train, X_test, target_train, target_test = train_test_split( X, target, test_size=0.1)\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=7)\n",
    "    clf = clf.fit(X_train, target_train)\n",
    "\n",
    "\n",
    "    print \"ctf accuracy score: \" , clf.score(X_test, target_test, sample_weight=None)\n",
    "    return clf, vectorizer, target.unique()\n",
    "ctf_civil, vec4,  label4 = createDT(df_CB_repeated[['Born', 'Famtype']], df_CB_repeated['Bydel'])\n",
    "ctf_person, vec2, label2 = createDT(df_KABP_repeated[['Kategori', 'Aldersgruppe']], df_KABP_repeated['Bydel'])\n",
    "ctf_person2, vec3, label1  = createDT(df_AHU_repeated[['Gruppe', 'Uddannelseskategori', 'Herkomst']], df_AHU_repeated['Bydel'])\n",
    "ctf_bolig, vec1, label1 = createDT(df_BEA_repeated[['EJERFORHOLD', 'SAMAREAL']], df_BEA_repeated['Bydel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the four decision trees perform quite similarly, and quite poorly.\n",
    "There are 10 dsitricts in Copenhagen so at random guessing one should have an accuracy of about 0.1.\n",
    "But by combining the predictive power of these four trees, one can possibly achieve a better prediction.\n",
    "Below are is a function for combining the predictions of the four trees, aka. forest.\n",
    "\n",
    "### accumulateProba\n",
    "accumulates the probalities that each tree has assigned to all the districts and returns the district that is appointed as the most probable district, by the forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(os.path.join(root_directory, \"notebooks\",\"mig.csv\"))\n",
    "def accumulateProba(ctf_bolig, ctf_person, ctf_person2, ctf_civil, vec1, vec2, vec3, vec4, persons):\n",
    "    mitHjem = persons[['EJERFORHOLD', 'SAMAREAL']].T.to_dict().values()\n",
    "\n",
    "    mig = persons[['Kategori', 'Aldersgruppe']].T.to_dict().values()\n",
    "\n",
    "    mereMig = persons[['Gruppe', 'Uddannelseskategori', 'Herkomst']].T.to_dict().values()\n",
    "\n",
    "    migOgDig = persons[['Born', 'Famtype']].T.to_dict().values()\n",
    "\n",
    "    X1 = vec1.transform(mitHjem)\n",
    "    X2 = vec2.transform(mig)\n",
    "    X3 = vec3.transform(mereMig)\n",
    "    X4 = vec4.transform(migOgDig)\n",
    "    answer1 = ctf_bolig.predict_proba(X1)\n",
    "    answer2 = ctf_person.predict_proba(X2)\n",
    "    answer3 = ctf_person2.predict_proba(X3)\n",
    "    answer4 = ctf_civil.predict_proba(X4)\n",
    "    answers = answer1 + answer2 + answer3 + answer4\n",
    "    index = [np.argmax(x) for x in answers]\n",
    "    result = []\n",
    "    for i in index:\n",
    "        result.append(ctf_bolig.classes_[i].decode('utf-8'))\n",
    "    return result\n",
    "print accumulateProba(ctf_bolig, ctf_person, ctf_person2, ctf_civil, vec1, vec2, vec3, vec4, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we would like to show you the code that we used to export the decision tree classifier to javascript and eventually to our website. http://valentinibanez.github.io/assignmentB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "tree.export_graphviz(ctf_bolig, out_file=dot_data,  \n",
    "                         feature_names=vec1.get_feature_names(),  \n",
    "                         class_names=ctf_bolig.classes_,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "def get_code(tree, feature_names):\n",
    "        left      = tree.tree_.children_left\n",
    "        right     = tree.tree_.children_right\n",
    "        threshold = tree.tree_.threshold\n",
    "        features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "        value = tree.tree_.value\n",
    "\n",
    "        def recurse(left, right, threshold, features, node):\n",
    "                if (threshold[node] != -2):\n",
    "                        print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"\n",
    "                        if left[node] != -1:\n",
    "                                recurse (left, right, threshold, features,left[node])\n",
    "                        print \"} else {\"\n",
    "                        if right[node] != -1:\n",
    "                                recurse (left, right, threshold, features,right[node])\n",
    "                        print \"}\"\n",
    "                else:\n",
    "                        print \"return \" + \"[[\" + \",\".join(map(str,value[node][0])) + \"]]\" + \";\"\n",
    "\n",
    "        recurse(left, right, threshold, features, 0)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_code(ctf_civil, vec4.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
